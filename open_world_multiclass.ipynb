{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roZZ8k0RMOBT"
      },
      "source": [
        "## Open World (unmon_standard10.pkl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGeFbOrFMOUj"
      },
      "source": [
        "### 1. Data Cleaning & Pre-processing\n",
        "**unmon_standard10.pkl**: This file includes data from \"unmonitored\" websites.\n",
        "\n",
        "   - Instances: 10,000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6gsSBqcCs__",
        "outputId": "28cbec47-58d7-45d7-a8c3-8d17c9e18428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT6b-dzuCvcd"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKMiQMC3arxu"
      },
      "outputs": [],
      "source": [
        "# Load monitored instances\n",
        "\n",
        "# Load X1\n",
        "with open('/content/drive/My Drive/Machine Learning Project/CODES/X1.pkl', 'rb') as file:\n",
        "    X1 = pickle.load(file)\n",
        "\n",
        "# Load X2\n",
        "with open('/content/drive/My Drive/Machine Learning Project/CODES/X2.pkl', 'rb') as file:\n",
        "    X2 = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/My Drive/Machine Learning Project/CODES/y.pkl', 'rb') as file:\n",
        "    y = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a partial dataset to keep class balance\n",
        "import random\n",
        "\n",
        "num_samples_per_y = y.count(0)\n",
        "num_sample = int(num_samples_per_y/2)\n",
        "\n",
        "# Initialize lists to store sampled values\n",
        "sampled_X1 = []\n",
        "sampled_X2 = []\n",
        "sampled_y = []\n",
        "\n",
        "# Randomly sample num_sample=100 values for each value of y\n",
        "unique_y_values = set(y)\n",
        "for val in unique_y_values:\n",
        "    indices_for_y = [idx for idx, value in enumerate(y) if value == val]\n",
        "    sampled_indices = random.sample(indices_for_y, num_sample)\n",
        "    sampled_X1.extend([X1[i] for i in sampled_indices])\n",
        "    sampled_X2.extend([X2[i] for i in sampled_indices])\n",
        "    sampled_y.extend([y[i] for i in sampled_indices])\n",
        "\n",
        "# Verify the lengths of sampled lists\n",
        "print(\"Sampled X1 length:\", len(sampled_X1))\n",
        "print(\"Sampled X2 length:\", len(sampled_X2))\n",
        "print(\"Sampled y length:\", len(sampled_y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4XhX-KEGquL",
        "outputId": "a1e5962a-f058-42c2-92ca-cb36a6c9818a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled X1 length: 9500\n",
            "Sampled X2 length: 9500\n",
            "Sampled y length: 9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = sampled_X1\n",
        "X2 = sampled_X2\n",
        "y = sampled_y"
      ],
      "metadata": {
        "id": "mmjM31XKIYOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZpiRUU0ZsQf"
      },
      "outputs": [],
      "source": [
        "# Load unmonitored instances\n",
        "\n",
        "# Load X1\n",
        "with open('/content/drive/My Drive/Machine Learning Project/CODES/X1_unmonitored.pkl', 'rb') as file:\n",
        "    X1_unmonitored = pickle.load(file)\n",
        "\n",
        "# Load X2\n",
        "with open('/content/drive/My Drive/Machine Learning Project/CODES/X2_unmonitored.pkl', 'rb') as file:\n",
        "    X2_unmonitored = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g33uZHiRa1Gg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb67654-1eea-45f0-988c-68b4c2306625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled X1_unmonitored length: 100\n",
            "Sampled X2_unmonitored length: 100\n"
          ]
        }
      ],
      "source": [
        "# Get a partial dataset to keep class balance\n",
        "\n",
        "# Randomly select a subset of indices\n",
        "selected_indices = np.random.choice(len(X1_unmonitored), num_sample, replace=False)\n",
        "\n",
        "# Use these indices to extract the subset of data\n",
        "X1_unmonitored = [X1_unmonitored[i] for i in selected_indices]\n",
        "X2_unmonitored = [X2_unmonitored[i] for i in selected_indices]\n",
        "\n",
        "# Verify the lengths of sampled lists\n",
        "print(\"Sampled X1_unmonitored length:\", len(X1_unmonitored))\n",
        "print(\"Sampled X2_unmonitored length:\", len(X2_unmonitored))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNL2xy3_bPTG"
      },
      "outputs": [],
      "source": [
        "# Create list of zeroes for unmonitored instances\n",
        "y_unmonitored = [-1] * num_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-F_aLj-bS9H"
      },
      "outputs": [],
      "source": [
        "# Concatenate monitored and unmonitored instances into 1 list for each array\n",
        "X1.extend(X1_unmonitored)\n",
        "X2.extend(X2_unmonitored)\n",
        "y.extend(y_unmonitored)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMBp1aYON7u7"
      },
      "source": [
        "### 2a. Feature Extraction (Continuous Features)\n",
        "\n",
        "1. Sequence of packet timestamps (X1)\n",
        "2. Sequence of packet sizes (X2)\n",
        "3. Sequence of cumulative packet sizes\n",
        "4. Sequence of bursts\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asqfZXLYDe-K"
      },
      "source": [
        "Continuous Feature 3: Sequence of Cumulative Packet Sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmyMa-qfBtPG",
        "outputId": "01800d4b-5792-465d-d994-81b0c4255c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 values of cumulative sizes:\n",
            "[ -512 -1024  -512 -1024  -512 -1024  -512     0  -512 -1024]\n"
          ]
        }
      ],
      "source": [
        "# Compute the cumulative sum for each sequence\n",
        "cumulative_sizes = [np.cumsum(seq) for seq in X2]\n",
        "\n",
        "# Print the first 10 values of the cumulative sizes for the 1st element\n",
        "print(\"First 10 values of cumulative sizes:\")\n",
        "print(cumulative_sizes[0][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNawaHgnDtag"
      },
      "source": [
        "Continuous Feature 4: Sequence of Bursts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnhvsUz_Dyy_",
        "outputId": "f7fb67ec-5ae2-4956-ebc6-4ac3681fcc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999999999987, 0.0, 0.0, 0.0]\n",
            "[-1024, 512, -512, 512, -512, 1024, -7168, 512, -512, 512]\n"
          ]
        }
      ],
      "source": [
        "def calculate_bursts_and_durations(X1, X2):\n",
        "    seq_of_bursts = []\n",
        "    burst_duration = []\n",
        "\n",
        "    for timestamps, sizes in zip(X1, X2):\n",
        "        burst = []\n",
        "        duration = []\n",
        "\n",
        "        current_size = 0\n",
        "        current_time = 0.0\n",
        "\n",
        "        time_start = 0.0\n",
        "\n",
        "        for time, size in zip(timestamps, sizes):\n",
        "          if current_size == 0 or (size > 0 and current_size > 0) or (size < 0 and current_size < 0):\n",
        "              current_size += size\n",
        "              current_time = time - time_start\n",
        "          else:\n",
        "              burst.append(current_size)\n",
        "              duration.append(current_time)\n",
        "              current_size = size\n",
        "              current_time = 0.0\n",
        "              time_start = time\n",
        "\n",
        "        burst.append(current_size)\n",
        "        duration.append(time-time_start)\n",
        "        seq_of_bursts.append(burst)\n",
        "        burst_duration.append(duration)\n",
        "\n",
        "    return burst_duration, seq_of_bursts\n",
        "\n",
        "burst_duration, seq_of_bursts = calculate_bursts_and_durations(X1, X2)\n",
        "\n",
        "print(burst_duration[0][:10])\n",
        "print(seq_of_bursts[0][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4HCd_RGOvh3"
      },
      "source": [
        "### 2b. Feature Extraction (Categorical Features)\n",
        "\n",
        "\n",
        "1. Number of incoming packets\n",
        "2. Number of incoming packets as a fraction of the total number of packets\n",
        "3. Number of outgoing packets\n",
        "4. Number of outgoing packets as a fraction of the total number of packets\n",
        "5. Total number of packets.\n",
        "6. Packet rate\n",
        "7. Incoming packet rate (client to server)\n",
        "8. Outgoing packet rate (server to client)\n",
        "9. Average time gap\n",
        "10. Total incoming bytes\n",
        "11. Total outgoing bytes\n",
        "12. Total incoming bursts\n",
        "13. Total outgoing bursts\n",
        "14. Total bursts\n",
        "15. Average Inter-arrival time for incoming packets per sample\n",
        "16. Average inter-departure time for outgoing packets per sample\n",
        "17. Total burst duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoSK2qUtT7G2",
        "outputId": "5fc9473f-944e-4867-ebc4-fbe26766b3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incoming Packets Array:\n",
            "[562, 492, 175, 634, 482, 1635, 1645, 145, 283, 550]\n",
            "\n",
            "Fraction of Incoming Packets Array:\n",
            "[0.0712113532691333, 0.05, 0.09610104338275673, 0.06372499748718465, 0.04886455798864558, 0.31545437005595217, 0.31507374066270827, 0.06508078994614004, 0.15943661971830986, 0.07105025190543858]\n",
            "\n",
            "Outgoing Packets Array:\n",
            "[7330, 9348, 1646, 9315, 9382, 3548, 3576, 2083, 1492, 7191]\n",
            "\n",
            "Fraction of Outgoing Packets Array:\n",
            "[0.9287886467308667, 0.95, 0.9038989566172433, 0.9362750025128154, 0.9511354420113545, 0.6845456299440479, 0.6849262593372917, 0.9349192100538599, 0.8405633802816901, 0.9289497480945614]\n"
          ]
        }
      ],
      "source": [
        "# 1. Number of incoming packets\n",
        "incoming_packets = [sum(1 for size in size_seq if size > 0) for size_seq in X2]\n",
        "\n",
        "# 2. Number of incoming packets as a fraction of the total number of packets\n",
        "fraction_incoming_packets = [sum(1 for size in size_seq if size > 0) / len(size_seq) for size_seq in X2]\n",
        "\n",
        "# 3. Number of outgoing packets\n",
        "outgoing_packets = [sum(1 for size in size_seq if size < 0) for size_seq in X2]\n",
        "\n",
        "# 4. Number of outgoing packets as a fraction of the total number of packets\n",
        "fraction_outgoing_packets = [sum(1 for size in size_seq if size < 0) / len(size_seq) for size_seq in X2]\n",
        "\n",
        "# Print first 10 values of the resulting arrays\n",
        "print(\"Incoming Packets Array:\")\n",
        "print(incoming_packets[:10])\n",
        "\n",
        "print(\"\\nFraction of Incoming Packets Array:\")\n",
        "print(fraction_incoming_packets[:10])\n",
        "\n",
        "print(\"\\nOutgoing Packets Array:\")\n",
        "print(outgoing_packets[:10])\n",
        "\n",
        "print(\"\\nFraction of Outgoing Packets Array:\")\n",
        "print(fraction_outgoing_packets[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_oBZbNJZ9_z",
        "outputId": "0c2c7bd1-3e8b-4f19-f99b-4960789b0623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Packets Array:\n",
            "[7892, 9840, 1821, 9949, 9864, 5183, 5221, 2228, 1775, 7741]\n",
            "\n",
            "Packet Rate:\n",
            "[364.1901245962159, 414.3157894736842, 98.91363389462249, 831.8561872909698, 854.0259740259739, 260.84549572219424, 282.98102981029814, 198.92857142857144, 46.97009790949987, 400.25853154084797]\n",
            "\n",
            "Incoming Packet Rate:\n",
            "[25.934471619750806, 20.71578947368421, 9.505703422053232, 53.01003344481605, 41.73160173160173, 82.28485153497735, 89.15989159891599, 12.946428571428573, 7.488753638528712, 28.43846949327818]\n",
            "\n",
            "Outgoing Packet Rate:\n",
            "[338.2556529764651, 393.6, 89.40793047256925, 778.8461538461538, 812.2943722943722, 178.5606441872169, 193.82113821138213, 185.98214285714286, 39.48134427097116, 371.8200620475698]\n"
          ]
        }
      ],
      "source": [
        "# 5. Total number of packets\n",
        "total_packets = [len(size_seq) for size_seq in X2]\n",
        "\n",
        "# 6. Packet Rate: Calculate the rate of packet arrival for each sequence\n",
        "packet_rate = [len(seq) / (max(seq) - min(seq)) if len(seq) > 1 else 0 for seq in X1]\n",
        "\n",
        "# 7. Incoming packet rate (client to server)\n",
        "incoming_packet_rate = [sum(1 for size in sizes if size > 0) / (max(seq) - min(seq)) if len(seq) > 1 else 0 for seq, sizes in zip(X1, X2)]\n",
        "\n",
        "# 8. Outgoing packet rate (server to client)\n",
        "outgoing_packet_rate = [sum(1 for size in sizes if size < 0) / (max(seq) - min(seq)) if len(seq) > 1 else 0 for seq, sizes in zip(X1, X2)]\n",
        "\n",
        "print(\"Total Packets Array:\")\n",
        "print(total_packets[:10])\n",
        "\n",
        "print(\"\\nPacket Rate:\")\n",
        "print(packet_rate[:10])\n",
        "\n",
        "print(\"\\nIncoming Packet Rate:\")\n",
        "print(incoming_packet_rate[:10])\n",
        "\n",
        "print(\"\\nOutgoing Packet Rate:\")\n",
        "print(outgoing_packet_rate[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtngxnPAb01q",
        "outputId": "52f94b94-4397-42a9-d35c-9bd2909e6148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Time Gaps:\n",
            "[0.002746166518818908, 0.0024138631974794187, 0.010115384615384615, 0.0012022517088862083, 0.001171043293115685, 0.003834426862215361, 0.0035344827586206895, 0.0050291872474180505, 0.021302142051860203, 0.002498708010335917]\n"
          ]
        }
      ],
      "source": [
        "# 9. Average Time Gap: Calculate the average time gap for each sequence in X1\n",
        "avg_time_gaps = []\n",
        "\n",
        "for seq in X1:\n",
        "    if len(seq) > 1:\n",
        "        time_gaps_sum = sum(j - i for i, j in zip(seq, seq[1:]))\n",
        "        avg_time_gap = time_gaps_sum / (len(seq) - 1)  # Subtract 1 because there are len(seq) - 1 time gaps\n",
        "        avg_time_gaps.append(avg_time_gap)\n",
        "    else:\n",
        "        avg_time_gaps.append(0)\n",
        "\n",
        "print(\"\\nAverage Time Gaps:\")\n",
        "print(avg_time_gaps[:10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 & 11. Total incoming and outgoing bytes\n",
        "incoming_bytes = []\n",
        "outgoing_bytes = []\n",
        "\n",
        "for sample in X2:\n",
        "    incoming = sum(size for size in sample if size > 0)\n",
        "    outgoing = abs(sum(size for size in sample if size < 0))\n",
        "\n",
        "    incoming_bytes.append(incoming)\n",
        "    outgoing_bytes.append(outgoing)\n",
        "\n",
        "# Print total incoming and outgoing bytes for the first 10 samples\n",
        "print(f'Incoming Bytes: {incoming_bytes[:10]}')\n",
        "print(f'Outgoing Bytes: {outgoing_bytes[:10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWhjePw_TQQM",
        "outputId": "ff9b6c3e-81d4-42d5-aada-d0ac1df85584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incoming Bytes: [287744, 251904, 89600, 324608, 246784, 837120, 842240, 74240, 144896, 281600]\n",
            "Outgoing Bytes: [3752960, 4786176, 842752, 4769280, 4803584, 1816576, 1830912, 1066496, 763904, 3681792]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12 & 13. Number of incoming and outgoing burst\n",
        "\n",
        "total_incoming_bursts = []\n",
        "total_outgoing_bursts = []\n",
        "\n",
        "# Calculate total number of incoming and outgoing bursts for all samples\n",
        "for sample in seq_of_bursts:\n",
        "  incoming_bursts = sum(1 for val in sample if val > 0)\n",
        "  outgoing_bursts = sum(1 for val in sample if val < 0)\n",
        "\n",
        "  total_incoming_bursts.append(incoming_bursts)\n",
        "  total_outgoing_bursts.append(outgoing_bursts)\n",
        "\n",
        "# 14. Calculate burst count for each sample\n",
        "burst_count = [len(bursts) for bursts in seq_of_bursts]\n",
        "\n",
        "# Print total incoming and outgoing bursts for first 10 samples\n",
        "print(f\"Total Incoming Bursts: {total_incoming_bursts[:10]}\")\n",
        "print(f\"Total Outgoing Bursts: {total_outgoing_bursts[:10]}\")\n",
        "print(f\"Burst Count: {burst_count[:10]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE_p_eExYfO9",
        "outputId": "eb599361-7f56-46eb-cee4-56b63c7fa52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Incoming Bursts: [340, 350, 98, 364, 345, 211, 197, 95, 115, 333]\n",
            "Total Outgoing Bursts: [340, 350, 98, 365, 345, 211, 197, 95, 116, 333]\n",
            "Burst Count: [680, 700, 196, 729, 690, 422, 394, 190, 231, 666]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Calculate average inter-arrival time for incoming packets per sample\n",
        "avg_interarrival_times = []\n",
        "\n",
        "for idx, (sample_packets, sample_directions) in enumerate(zip(X1, X2)):\n",
        "    incoming_packet_times = []\n",
        "\n",
        "    # Filter incoming packets based on positive direction values\n",
        "    incoming_packet_times = [packet_time for packet_time, direction in zip(sample_packets, sample_directions) if direction > 0]\n",
        "\n",
        "    if len(incoming_packet_times) <= 1:\n",
        "        # If only one or no incoming packet in the sample, assign 0 average inter-arrival time\n",
        "        avg_interarrival_times.append(0)\n",
        "    else:\n",
        "        # Calculate inter-arrival times between incoming packets\n",
        "        interarrival_times = [incoming_packet_times[i + 1] - incoming_packet_times[i] for i in range(len(incoming_packet_times) - 1)]\n",
        "\n",
        "        # Compute the average inter-arrival time for incoming packets\n",
        "        avg_interarrival_time = sum(interarrival_times) / len(interarrival_times)\n",
        "        avg_interarrival_times.append(avg_interarrival_time)\n",
        "\n",
        "# Print average inter-arrival time for incoming packets per sample\n",
        "print(\"Average inter-arrival time for incoming packets per sample:\")\n",
        "for i, avg_interarrival_time in enumerate(avg_interarrival_times[:10], start=1):\n",
        "    print(f\"Sample {i}: {avg_interarrival_time}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-enbabn_aG_S",
        "outputId": "1faeb41f-ddd6-42a5-a032-8cf837f4b4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average inter-arrival time for incoming packets per sample:\n",
            "Sample 1: 0.03841354723707665\n",
            "Sample 2: 0.04798370672097759\n",
            "Sample 3: 0.10517241379310344\n",
            "Sample 4: 0.018278041074249605\n",
            "Sample 5: 0.023762993762993765\n",
            "Sample 6: 0.012086903304773562\n",
            "Sample 7: 0.011137469586374698\n",
            "Sample 8: 0.07694444444444443\n",
            "Sample 9: 0.1324468085106383\n",
            "Sample 10: 0.03493624772313297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Calculate average inter-departure time for outgoing packets per sample\n",
        "avg_interdepart_times = []\n",
        "\n",
        "for idx, (sample_packets, sample_directions) in enumerate(zip(X1, X2)):\n",
        "    outgoing_packet_times = []\n",
        "\n",
        "    # Filter outgoing packets based on negative direction values\n",
        "    outgoing_packet_times = [packet_time for packet_time, direction in zip(sample_packets, sample_directions) if direction < 0]\n",
        "\n",
        "    if len(outgoing_packet_times) <= 1:\n",
        "        # If only one or no outgoing packet in the sample, assign 0 average inter-arrival time\n",
        "        avg_interdepart_times.append(0)\n",
        "    else:\n",
        "        # Calculate inter-arrival times between outgoing packets\n",
        "        interdepart_times = [outgoing_packet_times[i + 1] - outgoing_packet_times[i] for i in range(len(outgoing_packet_times) - 1)]\n",
        "\n",
        "        # Compute the average inter-arrival time for outgoing packets\n",
        "        avg_interdepart_time = sum(interdepart_times) / len(interdepart_times)\n",
        "        avg_interdepart_times.append(avg_interdepart_time)\n",
        "\n",
        "# Print average inter-arrival time for outgoing packets per sample\n",
        "print(\"Average inter-arrival time for outgoing packets per sample:\")\n",
        "for i, avg_interdepart_time in enumerate(avg_interdepart_times[:10], start=1):\n",
        "    print(f\"Sample {i}: {avg_interdepart_time}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUrCIrXRiDiq",
        "outputId": "a999b6ce-5cc7-43de-9341-adea04f5b721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average inter-arrival time for outgoing packets per sample:\n",
            "Sample 1: 0.002956747168781553\n",
            "Sample 2: 0.002540922221033487\n",
            "Sample 3: 0.011191489361702127\n",
            "Sample 4: 0.001284088468971441\n",
            "Sample 5: 0.001073446327683616\n",
            "Sample 6: 0.005599097829151395\n",
            "Sample 7: 0.005160839160839161\n",
            "Sample 8: 0.003208453410182517\n",
            "Sample 9: 0.02534540576794098\n",
            "Sample 10: 0.002689847009735744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. Total burst duration\n",
        "total_burst_duration = [sum(duration) for duration in burst_duration]\n",
        "print(total_burst_duration[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OETtb0FqHi4T",
        "outputId": "b1fca3ee-5c3b-4101-8259-d22b7c934c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14.099999999999996, 14.029999999999998, 4.9000000000000075, 5.380000000000004, 5.92, 6.0600000000000005, 11.999999999999998, 6.530000000000001, 27.4, 9.940000000000003]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJGbc-CLVQio"
      },
      "source": [
        "### 3a. Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = [\n",
        "    incoming_packets,\n",
        "    fraction_incoming_packets,\n",
        "    outgoing_packets,\n",
        "    fraction_outgoing_packets,\n",
        "    total_packets,\n",
        "    # packet_rate,\n",
        "    # incoming_packet_rate,\n",
        "    # outgoing_packet_rate,\n",
        "    # avg_time_gaps,\n",
        "    incoming_bytes,\n",
        "    outgoing_bytes,\n",
        "    total_incoming_bursts,\n",
        "    total_outgoing_bursts,\n",
        "    burst_count,\n",
        "    avg_interarrival_times,\n",
        "    avg_interdepart_times,\n",
        "    total_burst_duration\n",
        "]\n",
        "\n",
        "# Feature importance (code is in feature_selection.ipynb)\n",
        "# total_packets: 0.08391385637928211\n",
        "# fraction_incoming_packets: 0.07525438164233617\n",
        "# outgoing_packets: 0.07397300171079065\n",
        "# fraction_outgoing_packets: 0.07302431700858097\n",
        "# outgoing_bytes: 0.07264166480526325\n",
        "# incoming_bytes: 0.06342574766295982\n",
        "# incoming_packets: 0.06198666583613548\n",
        "# total_burst_duration: 0.05929302192406632\n",
        "# burst_count: 0.05624511174559692\n",
        "# total_outgoing_bursts: 0.05452631240160152\n",
        "# total_incoming_bursts: 0.05417409771603582\n",
        "# avg_interarrival_times: 0.051337481385899435\n",
        "# avg_interdepart_times: 0.04994909975727552\n",
        "# incoming_packet_rate: 0.047878438278210256\n",
        "# outgoing_packet_rate: 0.04129542002349407\n",
        "# packet_rate: 0.040831661921218544\n",
        "# avg_time_gaps: 0.04024971980125318\n",
        "\n",
        "# Transpose the feature matrix X to have samples as rows and features as columns\n",
        "X = np.array(X).T\n",
        "\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "kCX9klPOMgte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'GradientBoosting': GradientBoostingClassifier(),\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Iterate through models\n",
        "for model_name, model in models.items():\n",
        "    # Use GridSearchCV for hyperparameter tuning\n",
        "    param_grid = {}\n",
        "\n",
        "    if model_name == 'RandomForest':\n",
        "        param_grid = {'n_estimators': [50, 100, 200],\n",
        "                      'max_depth': [None, 10, 20],\n",
        "                      'min_samples_split': [2, 5, 10],\n",
        "                      'min_samples_leaf': [1, 2, 4]}\n",
        "    elif model_name == 'GradientBoosting':\n",
        "        param_grid = {'n_estimators': [50, 100, 200],\n",
        "                      'learning_rate': [0.01, 0.1, 0.2],\n",
        "                      'max_depth': [3, 5, 7]}\n",
        "    elif model_name == 'KNN':\n",
        "        param_grid = {'n_neighbors': [3, 5, 7, 9],\n",
        "                      'weights': ['uniform', 'distance'],\n",
        "                      'p': [1, 2]}\n",
        "\n",
        "    # Create GridSearchCV object\n",
        "    grid = GridSearchCV(model, param_grid, refit=True, verbose=3, n_jobs=-1)\n",
        "\n",
        "    # Use cross-validation to get more reliable performance estimates\n",
        "    cv_scores = cross_val_score(grid, X_scaled, y, cv=5)\n",
        "    print(f\"Cross-validated {model_name} Accuracy: {np.mean(cv_scores):.2f} (± {np.std(cv_scores):.2f})\")\n",
        "\n",
        "    # Train the model on the entire training set\n",
        "    grid.fit(X_scaled, y)\n",
        "\n",
        "    # Print the best parameters and estimator\n",
        "    print(f\"Best parameters for {model_name}: {grid.best_params_}\")\n",
        "    print(f\"Best estimator for {model_name}: {grid.best_estimator_}\")\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = grid.predict(X_scaled)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n",
        "    print(classification_report(y, y_pred))"
      ],
      "metadata": {
        "id": "7Q-67W9LzhZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0GXhG1Ic7Mf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ca1b34dd-a630-4fb2-c241-dcd4168136f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Create the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq0SWeV9dfuA"
      },
      "source": [
        "### 3b. Model Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v-t_cSPdDxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6daa6486-cd19-4d63-e97e-d644942596ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.48\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00        27\n",
            "           0       0.60      0.47      0.53        38\n",
            "           1       0.22      0.27      0.24        26\n",
            "           2       0.67      0.75      0.71        24\n",
            "           3       0.53      0.43      0.48        23\n",
            "           4       0.40      0.43      0.42        23\n",
            "           5       0.63      0.46      0.53        26\n",
            "           6       0.57      0.54      0.55        24\n",
            "           7       0.57      0.43      0.49        30\n",
            "           8       0.57      0.62      0.59        21\n",
            "           9       0.42      0.55      0.48        20\n",
            "          10       0.44      0.24      0.31        29\n",
            "          11       0.41      0.26      0.32        27\n",
            "          12       0.70      0.86      0.78        22\n",
            "          13       0.26      0.33      0.29        24\n",
            "          14       0.41      0.43      0.42        28\n",
            "          15       0.61      0.63      0.62        27\n",
            "          16       0.64      0.52      0.57        27\n",
            "          17       0.37      0.38      0.37        29\n",
            "          18       0.83      0.83      0.83        18\n",
            "          19       0.40      0.67      0.50        18\n",
            "          20       1.00      0.75      0.86        24\n",
            "          21       0.18      0.10      0.13        30\n",
            "          22       0.32      0.24      0.27        29\n",
            "          23       0.50      0.68      0.58        19\n",
            "          24       0.12      0.12      0.12        25\n",
            "          25       0.26      0.33      0.29        18\n",
            "          26       0.62      0.72      0.67        25\n",
            "          27       0.39      0.55      0.45        22\n",
            "          28       0.63      0.73      0.68        26\n",
            "          29       0.56      0.37      0.44        27\n",
            "          30       0.79      0.55      0.65        42\n",
            "          31       0.90      0.60      0.72        30\n",
            "          32       0.32      0.50      0.39        18\n",
            "          33       0.52      0.57      0.54        23\n",
            "          34       0.18      0.13      0.15        23\n",
            "          35       0.50      0.55      0.52        22\n",
            "          36       0.48      0.48      0.48        21\n",
            "          37       0.27      0.39      0.32        23\n",
            "          38       0.33      0.40      0.36        20\n",
            "          39       0.57      0.59      0.58        29\n",
            "          40       0.48      0.45      0.46        29\n",
            "          41       0.79      0.68      0.73        28\n",
            "          42       0.29      0.27      0.28        30\n",
            "          43       0.72      0.58      0.64        31\n",
            "          44       1.00      0.84      0.91        19\n",
            "          45       0.22      0.32      0.26        22\n",
            "          46       0.44      0.41      0.42        34\n",
            "          47       0.32      0.34      0.33        29\n",
            "          48       0.60      0.44      0.51        27\n",
            "          49       0.68      0.81      0.74        26\n",
            "          50       0.55      0.52      0.53        23\n",
            "          51       0.22      0.24      0.23        21\n",
            "          52       0.46      0.44      0.45        25\n",
            "          53       0.17      0.24      0.20        25\n",
            "          54       0.50      0.58      0.54        19\n",
            "          55       0.28      0.24      0.26        21\n",
            "          56       0.78      0.82      0.80        22\n",
            "          57       0.57      0.45      0.50        29\n",
            "          58       0.89      0.64      0.74        25\n",
            "          59       0.68      0.58      0.62        26\n",
            "          60       0.46      0.50      0.48        24\n",
            "          61       0.31      0.46      0.37        24\n",
            "          62       0.58      0.48      0.52        23\n",
            "          63       0.55      0.39      0.46        28\n",
            "          64       0.45      0.68      0.54        28\n",
            "          65       0.47      0.38      0.42        24\n",
            "          66       0.60      0.64      0.62        28\n",
            "          67       0.58      0.68      0.62        22\n",
            "          68       0.26      0.35      0.30        23\n",
            "          69       0.48      0.31      0.38        32\n",
            "          70       0.75      0.88      0.81        24\n",
            "          71       0.35      0.40      0.38        15\n",
            "          72       0.42      0.58      0.49        19\n",
            "          73       0.74      0.77      0.76        22\n",
            "          74       0.16      0.14      0.15        28\n",
            "          75       0.71      0.83      0.77        24\n",
            "          76       0.79      0.93      0.85        28\n",
            "          77       0.38      0.34      0.36        29\n",
            "          78       0.19      0.19      0.19        26\n",
            "          79       0.32      0.33      0.33        24\n",
            "          80       0.62      0.58      0.60        26\n",
            "          81       0.39      0.42      0.41        31\n",
            "          82       0.39      0.35      0.37        20\n",
            "          83       0.57      0.73      0.64        22\n",
            "          84       0.30      0.29      0.30        24\n",
            "          85       0.55      0.68      0.61        25\n",
            "          86       0.96      0.96      0.96        25\n",
            "          87       0.54      0.28      0.37        25\n",
            "          88       0.41      0.32      0.36        22\n",
            "          89       0.20      0.27      0.23        22\n",
            "          90       0.42      0.53      0.47        19\n",
            "          91       0.59      0.36      0.44        28\n",
            "          92       0.38      0.41      0.39        22\n",
            "          93       0.88      0.79      0.83        28\n",
            "          94       0.44      0.39      0.42        28\n",
            "\n",
            "    accuracy                           0.48      2400\n",
            "   macro avg       0.49      0.49      0.49      2400\n",
            "weighted avg       0.50      0.48      0.48      2400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Get a classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=3, scoring='accuracy', refit = True, verbose = 3)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HXXpQlFqiY_w",
        "outputId": "c21680a9-0d91-476e-8f74-3ea5445ac630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "[CV 1/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.296 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.329 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.311 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.295 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.325 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.306 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.296 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.324 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.302 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.294 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.326 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.310 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.292 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.329 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.309 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.295 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.323 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.302 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.298 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.327 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.306 total time=   0.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.298 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.327 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.306 total time=   0.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.295 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.325 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.302 total time=   0.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=0.408 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=0.440 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=0.438 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5;, score=0.404 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5;, score=0.440 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5;, score=0.428 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10;, score=0.405 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10;, score=0.427 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10;, score=0.417 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=0.393 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=0.433 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=0.428 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=5;, score=0.392 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=5;, score=0.437 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=5;, score=0.425 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=10;, score=0.397 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=10;, score=0.429 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=10;, score=0.415 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=0.400 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=0.441 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=0.418 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=4, min_samples_split=5;, score=0.400 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=4, min_samples_split=5;, score=0.441 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=4, min_samples_split=5;, score=0.418 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=4, min_samples_split=10;, score=0.399 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=4, min_samples_split=10;, score=0.432 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=4, min_samples_split=10;, score=0.415 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2;, score=0.445 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2;, score=0.456 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2;, score=0.463 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5;, score=0.443 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5;, score=0.447 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5;, score=0.447 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10;, score=0.438 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10;, score=0.433 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10;, score=0.433 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2;, score=0.425 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2;, score=0.438 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2;, score=0.446 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5;, score=0.430 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5;, score=0.444 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5;, score=0.442 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10;, score=0.428 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10;, score=0.433 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10;, score=0.431 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2;, score=0.432 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2;, score=0.449 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2;, score=0.433 total time=   0.3s\n",
            "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5;, score=0.432 total time=   0.3s\n",
            "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5;, score=0.449 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5;, score=0.433 total time=   0.3s\n",
            "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10;, score=0.425 total time=   0.3s\n",
            "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10;, score=0.440 total time=   0.3s\n",
            "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10;, score=0.431 total time=   0.2s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.438 total time=   0.9s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.444 total time=   1.0s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.430 total time=   0.9s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.434 total time=   1.0s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.445 total time=   1.0s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.425 total time=   1.0s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.425 total time=   0.7s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.438 total time=   0.6s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.416 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.432 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.445 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.425 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.427 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.444 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.422 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.425 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.432 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.413 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.431 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.438 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.414 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.431 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.438 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.414 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.424 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.436 total time=   0.8s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.416 total time=   0.9s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=0.463 total time=   1.0s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=0.475 total time=   1.0s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=0.464 total time=   1.0s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5;, score=0.452 total time=   1.0s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5;, score=0.469 total time=   1.0s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5;, score=0.452 total time=   1.0s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10;, score=0.435 total time=   0.6s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10;, score=0.435 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10;, score=0.429 total time=   0.6s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=0.441 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=0.452 total time=   0.6s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=0.447 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=5;, score=0.445 total time=   0.6s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=5;, score=0.451 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=5;, score=0.444 total time=   0.6s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=10;, score=0.432 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=10;, score=0.437 total time=   0.6s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=10;, score=0.425 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=0.439 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=0.444 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=0.433 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=5;, score=0.439 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=5;, score=0.444 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=5;, score=0.433 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=10;, score=0.433 total time=   0.6s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=10;, score=0.435 total time=   0.9s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=10;, score=0.427 total time=   0.9s\n",
            "[CV 1/3] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2;, score=0.468 total time=   1.0s\n",
            "[CV 2/3] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2;, score=0.475 total time=   1.0s\n",
            "[CV 3/3] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2;, score=0.460 total time=   1.0s\n",
            "[CV 1/3] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5;, score=0.450 total time=   1.1s\n",
            "[CV 2/3] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5;, score=0.469 total time=   1.0s\n",
            "[CV 3/3] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5;, score=0.454 total time=   0.9s\n",
            "[CV 1/3] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10;, score=0.435 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10;, score=0.435 total time=   0.6s\n",
            "[CV 3/3] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10;, score=0.429 total time=   0.6s\n",
            "[CV 1/3] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2;, score=0.441 total time=   0.6s\n",
            "[CV 2/3] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2;, score=0.452 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2;, score=0.448 total time=   0.6s\n",
            "[CV 1/3] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5;, score=0.445 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5;, score=0.451 total time=   0.6s\n",
            "[CV 3/3] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5;, score=0.444 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10;, score=0.432 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10;, score=0.437 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10;, score=0.425 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2;, score=0.439 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2;, score=0.444 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2;, score=0.433 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5;, score=0.439 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5;, score=0.444 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5;, score=0.433 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10;, score=0.433 total time=   0.8s\n",
            "[CV 2/3] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10;, score=0.435 total time=   0.9s\n",
            "[CV 3/3] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10;, score=0.427 total time=   0.9s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [10, 15, 20],\n",
              "                         'min_samples_leaf': [1, 2, 4],\n",
              "                         'min_samples_split': [2, 5, 10]},\n",
              "             scoring='accuracy', verbose=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [10, 15, 20],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [10, 15, 20],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best parameters after grid search\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pumIeUEfjPD-",
        "outputId": "284b59dc-bfaf-46e1-ec55-11c43035052e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=20, random_state=42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluate the model with the best parameters\n",
        "grid_pred = grid_search.predict(X_test)\n",
        "print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test, grid_pred)))\n",
        "# Get a classification report\n",
        "print(classification_report(y_test, grid_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gD2cv04jYmq",
        "outputId": "642b839a-0318-48a1-d253-236f5daa2624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on test dataset: 0.49041666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00        27\n",
            "           0       0.42      0.34      0.38        38\n",
            "           1       0.28      0.31      0.29        26\n",
            "           2       0.62      0.83      0.71        24\n",
            "           3       0.38      0.43      0.41        23\n",
            "           4       0.62      0.35      0.44        23\n",
            "           5       0.41      0.35      0.38        26\n",
            "           6       0.71      0.83      0.77        24\n",
            "           7       0.50      0.27      0.35        30\n",
            "           8       0.70      0.67      0.68        21\n",
            "           9       0.35      0.55      0.43        20\n",
            "          10       0.50      0.28      0.36        29\n",
            "          11       0.43      0.33      0.38        27\n",
            "          12       0.67      0.91      0.77        22\n",
            "          13       0.40      0.25      0.31        24\n",
            "          14       0.43      0.36      0.39        28\n",
            "          15       0.56      0.67      0.61        27\n",
            "          16       0.59      0.48      0.53        27\n",
            "          17       0.33      0.28      0.30        29\n",
            "          18       0.74      0.78      0.76        18\n",
            "          19       0.38      0.67      0.48        18\n",
            "          20       1.00      0.79      0.88        24\n",
            "          21       0.14      0.10      0.12        30\n",
            "          22       0.25      0.10      0.15        29\n",
            "          23       0.50      0.58      0.54        19\n",
            "          24       0.12      0.16      0.14        25\n",
            "          25       0.36      0.28      0.31        18\n",
            "          26       0.71      0.68      0.69        25\n",
            "          27       0.46      0.50      0.48        22\n",
            "          28       0.47      0.62      0.53        26\n",
            "          29       0.44      0.44      0.44        27\n",
            "          30       0.71      0.52      0.60        42\n",
            "          31       0.65      0.57      0.61        30\n",
            "          32       0.30      0.39      0.34        18\n",
            "          33       0.40      0.52      0.45        23\n",
            "          34       0.22      0.17      0.20        23\n",
            "          35       0.54      0.59      0.57        22\n",
            "          36       0.44      0.57      0.50        21\n",
            "          37       0.31      0.48      0.37        23\n",
            "          38       0.28      0.35      0.31        20\n",
            "          39       0.61      0.66      0.63        29\n",
            "          40       0.65      0.52      0.58        29\n",
            "          41       0.82      0.64      0.72        28\n",
            "          42       0.29      0.33      0.31        30\n",
            "          43       0.79      0.61      0.69        31\n",
            "          44       1.00      0.89      0.94        19\n",
            "          45       0.35      0.41      0.38        22\n",
            "          46       0.71      0.59      0.65        34\n",
            "          47       0.38      0.34      0.36        29\n",
            "          48       0.69      0.41      0.51        27\n",
            "          49       0.73      0.73      0.73        26\n",
            "          50       0.61      0.48      0.54        23\n",
            "          51       0.30      0.38      0.33        21\n",
            "          52       0.50      0.48      0.49        25\n",
            "          53       0.31      0.36      0.33        25\n",
            "          54       0.41      0.63      0.50        19\n",
            "          55       0.22      0.24      0.23        21\n",
            "          56       0.74      0.91      0.82        22\n",
            "          57       0.54      0.48      0.51        29\n",
            "          58       0.73      0.64      0.68        25\n",
            "          59       0.74      0.65      0.69        26\n",
            "          60       0.59      0.54      0.57        24\n",
            "          61       0.52      0.50      0.51        24\n",
            "          62       0.70      0.61      0.65        23\n",
            "          63       0.46      0.39      0.42        28\n",
            "          64       0.34      0.43      0.38        28\n",
            "          65       0.55      0.46      0.50        24\n",
            "          66       0.57      0.43      0.49        28\n",
            "          67       0.50      0.68      0.58        22\n",
            "          68       0.38      0.43      0.41        23\n",
            "          69       0.40      0.38      0.39        32\n",
            "          70       0.81      0.88      0.84        24\n",
            "          71       0.15      0.33      0.21        15\n",
            "          72       0.36      0.47      0.41        19\n",
            "          73       0.71      0.77      0.74        22\n",
            "          74       0.37      0.36      0.36        28\n",
            "          75       0.77      0.83      0.80        24\n",
            "          76       0.83      0.89      0.86        28\n",
            "          77       0.28      0.24      0.26        29\n",
            "          78       0.27      0.31      0.29        26\n",
            "          79       0.23      0.25      0.24        24\n",
            "          80       0.68      0.58      0.62        26\n",
            "          81       0.48      0.48      0.48        31\n",
            "          82       0.36      0.40      0.38        20\n",
            "          83       0.48      0.68      0.57        22\n",
            "          84       0.45      0.38      0.41        24\n",
            "          85       0.67      0.64      0.65        25\n",
            "          86       1.00      0.96      0.98        25\n",
            "          87       0.58      0.56      0.57        25\n",
            "          88       0.45      0.45      0.45        22\n",
            "          89       0.17      0.23      0.20        22\n",
            "          90       0.41      0.58      0.48        19\n",
            "          91       0.54      0.46      0.50        28\n",
            "          92       0.38      0.41      0.39        22\n",
            "          93       0.68      0.61      0.64        28\n",
            "          94       0.38      0.36      0.37        28\n",
            "\n",
            "    accuracy                           0.49      2400\n",
            "   macro avg       0.50      0.50      0.49      2400\n",
            "weighted avg       0.50      0.49      0.49      2400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Random Forest"
      ],
      "metadata": {
        "id": "FF9w88fGLMpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier()\n",
        "\n",
        "# Train the model\n",
        "rf_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "4kxF2kw8jayL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "882ad7f6-2a4f-4ade-c517-c804d583754d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Get a classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qAJahzWJeDO",
        "outputId": "46b6bf74-368b-45b2-d1a1-187cbc772093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.62\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00        27\n",
            "           0       0.70      0.55      0.62        38\n",
            "           1       0.43      0.35      0.38        26\n",
            "           2       0.74      0.83      0.78        24\n",
            "           3       0.48      0.61      0.54        23\n",
            "           4       0.39      0.52      0.44        23\n",
            "           5       0.75      0.58      0.65        26\n",
            "           6       0.64      0.88      0.74        24\n",
            "           7       0.76      0.63      0.69        30\n",
            "           8       0.79      0.71      0.75        21\n",
            "           9       0.44      0.55      0.49        20\n",
            "          10       0.89      0.28      0.42        29\n",
            "          11       0.62      0.48      0.54        27\n",
            "          12       0.66      0.95      0.78        22\n",
            "          13       0.50      0.29      0.37        24\n",
            "          14       0.58      0.54      0.56        28\n",
            "          15       0.67      0.89      0.76        27\n",
            "          16       0.68      0.56      0.61        27\n",
            "          17       0.53      0.59      0.56        29\n",
            "          18       0.83      0.83      0.83        18\n",
            "          19       0.41      0.67      0.51        18\n",
            "          20       0.88      0.92      0.90        24\n",
            "          21       0.42      0.27      0.33        30\n",
            "          22       0.42      0.28      0.33        29\n",
            "          23       0.58      0.79      0.67        19\n",
            "          24       0.24      0.16      0.19        25\n",
            "          25       0.43      0.50      0.46        18\n",
            "          26       0.84      0.84      0.84        25\n",
            "          27       0.71      0.77      0.74        22\n",
            "          28       0.62      0.69      0.65        26\n",
            "          29       0.54      0.48      0.51        27\n",
            "          30       0.84      0.74      0.78        42\n",
            "          31       0.76      0.63      0.69        30\n",
            "          32       0.39      0.50      0.44        18\n",
            "          33       0.59      0.74      0.65        23\n",
            "          34       0.29      0.22      0.25        23\n",
            "          35       0.63      0.86      0.73        22\n",
            "          36       0.46      0.76      0.57        21\n",
            "          37       0.54      0.30      0.39        23\n",
            "          38       0.54      0.75      0.63        20\n",
            "          39       0.81      0.72      0.76        29\n",
            "          40       0.76      0.55      0.64        29\n",
            "          41       0.71      0.71      0.71        28\n",
            "          42       0.53      0.57      0.55        30\n",
            "          43       0.88      0.74      0.81        31\n",
            "          44       0.95      0.95      0.95        19\n",
            "          45       0.33      0.45      0.38        22\n",
            "          46       0.61      0.59      0.60        34\n",
            "          47       0.52      0.52      0.52        29\n",
            "          48       0.62      0.56      0.59        27\n",
            "          49       0.74      0.77      0.75        26\n",
            "          50       0.81      0.91      0.86        23\n",
            "          51       0.47      0.43      0.45        21\n",
            "          52       0.50      0.56      0.53        25\n",
            "          53       0.48      0.44      0.46        25\n",
            "          54       0.75      0.79      0.77        19\n",
            "          55       0.33      0.43      0.38        21\n",
            "          56       0.85      1.00      0.92        22\n",
            "          57       0.81      0.72      0.76        29\n",
            "          58       0.86      0.72      0.78        25\n",
            "          59       0.68      0.73      0.70        26\n",
            "          60       0.75      0.62      0.68        24\n",
            "          61       0.58      0.75      0.65        24\n",
            "          62       0.65      0.57      0.60        23\n",
            "          63       0.65      0.54      0.59        28\n",
            "          64       0.55      0.75      0.64        28\n",
            "          65       0.72      0.54      0.62        24\n",
            "          66       0.65      0.79      0.71        28\n",
            "          67       0.83      0.86      0.84        22\n",
            "          68       0.80      0.35      0.48        23\n",
            "          69       0.58      0.56      0.57        32\n",
            "          70       0.79      0.96      0.87        24\n",
            "          71       0.38      0.53      0.44        15\n",
            "          72       0.65      0.68      0.67        19\n",
            "          73       0.55      0.82      0.65        22\n",
            "          74       0.47      0.50      0.48        28\n",
            "          75       0.81      0.92      0.86        24\n",
            "          76       0.90      0.96      0.93        28\n",
            "          77       0.55      0.38      0.45        29\n",
            "          78       0.32      0.35      0.33        26\n",
            "          79       0.48      0.42      0.44        24\n",
            "          80       0.75      0.69      0.72        26\n",
            "          81       0.70      0.68      0.69        31\n",
            "          82       0.62      0.40      0.48        20\n",
            "          83       0.52      0.73      0.60        22\n",
            "          84       0.54      0.54      0.54        24\n",
            "          85       0.68      0.84      0.75        25\n",
            "          86       0.92      0.96      0.94        25\n",
            "          87       0.73      0.76      0.75        25\n",
            "          88       0.64      0.64      0.64        22\n",
            "          89       0.30      0.32      0.31        22\n",
            "          90       0.59      0.68      0.63        19\n",
            "          91       0.80      0.57      0.67        28\n",
            "          92       0.45      0.45      0.45        22\n",
            "          93       0.74      0.82      0.78        28\n",
            "          94       0.31      0.39      0.34        28\n",
            "\n",
            "    accuracy                           0.62      2400\n",
            "   macro avg       0.62      0.62      0.61      2400\n",
            "weighted avg       0.62      0.62      0.61      2400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. KNN & PCA"
      ],
      "metadata": {
        "id": "TKZsHGOqLHQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "D4_jqZI3MslB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Iterate over different values of n_neighbors\n",
        "for n in range(5, 51):\n",
        "    # Initialize k-NN classifier with the current n_neighbors value\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=n)\n",
        "\n",
        "    # Train the classifier and measure the time\n",
        "    start_time = time.time()\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Predictions & Accuracy\n",
        "    y_pred = knn_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in the dictionary\n",
        "    results[n] = {'accuracy': accuracy, 'training_time': training_time}\n",
        "\n",
        "# Print the results\n",
        "for n, metrics in results.items():\n",
        "    print(f\"n_neighbors = {n}: Accuracy = {metrics['accuracy']:.4f}, Training time = {metrics['training_time']:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4q68J8YNHpk",
        "outputId": "b289f424-8134-4ba0-b536-a52c68311dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_neighbors = 5: Accuracy = 0.3946, Training time = 0.02 seconds\n",
            "n_neighbors = 6: Accuracy = 0.3954, Training time = 0.02 seconds\n",
            "n_neighbors = 7: Accuracy = 0.4033, Training time = 0.02 seconds\n",
            "n_neighbors = 8: Accuracy = 0.4071, Training time = 0.04 seconds\n",
            "n_neighbors = 9: Accuracy = 0.4008, Training time = 0.02 seconds\n",
            "n_neighbors = 10: Accuracy = 0.3962, Training time = 0.02 seconds\n",
            "n_neighbors = 11: Accuracy = 0.3929, Training time = 0.02 seconds\n",
            "n_neighbors = 12: Accuracy = 0.3867, Training time = 0.03 seconds\n",
            "n_neighbors = 13: Accuracy = 0.3837, Training time = 0.02 seconds\n",
            "n_neighbors = 14: Accuracy = 0.3775, Training time = 0.02 seconds\n",
            "n_neighbors = 15: Accuracy = 0.3787, Training time = 0.02 seconds\n",
            "n_neighbors = 16: Accuracy = 0.3779, Training time = 0.02 seconds\n",
            "n_neighbors = 17: Accuracy = 0.3700, Training time = 0.01 seconds\n",
            "n_neighbors = 18: Accuracy = 0.3692, Training time = 0.01 seconds\n",
            "n_neighbors = 19: Accuracy = 0.3646, Training time = 0.01 seconds\n",
            "n_neighbors = 20: Accuracy = 0.3625, Training time = 0.01 seconds\n",
            "n_neighbors = 21: Accuracy = 0.3596, Training time = 0.01 seconds\n",
            "n_neighbors = 22: Accuracy = 0.3542, Training time = 0.01 seconds\n",
            "n_neighbors = 23: Accuracy = 0.3550, Training time = 0.01 seconds\n",
            "n_neighbors = 24: Accuracy = 0.3525, Training time = 0.02 seconds\n",
            "n_neighbors = 25: Accuracy = 0.3496, Training time = 0.02 seconds\n",
            "n_neighbors = 26: Accuracy = 0.3450, Training time = 0.02 seconds\n",
            "n_neighbors = 27: Accuracy = 0.3400, Training time = 0.02 seconds\n",
            "n_neighbors = 28: Accuracy = 0.3417, Training time = 0.02 seconds\n",
            "n_neighbors = 29: Accuracy = 0.3417, Training time = 0.02 seconds\n",
            "n_neighbors = 30: Accuracy = 0.3396, Training time = 0.02 seconds\n",
            "n_neighbors = 31: Accuracy = 0.3358, Training time = 0.02 seconds\n",
            "n_neighbors = 32: Accuracy = 0.3346, Training time = 0.03 seconds\n",
            "n_neighbors = 33: Accuracy = 0.3279, Training time = 0.02 seconds\n",
            "n_neighbors = 34: Accuracy = 0.3275, Training time = 0.03 seconds\n",
            "n_neighbors = 35: Accuracy = 0.3250, Training time = 0.02 seconds\n",
            "n_neighbors = 36: Accuracy = 0.3212, Training time = 0.02 seconds\n",
            "n_neighbors = 37: Accuracy = 0.3183, Training time = 0.02 seconds\n",
            "n_neighbors = 38: Accuracy = 0.3162, Training time = 0.02 seconds\n",
            "n_neighbors = 39: Accuracy = 0.3137, Training time = 0.02 seconds\n",
            "n_neighbors = 40: Accuracy = 0.3117, Training time = 0.02 seconds\n",
            "n_neighbors = 41: Accuracy = 0.3071, Training time = 0.02 seconds\n",
            "n_neighbors = 42: Accuracy = 0.3054, Training time = 0.02 seconds\n",
            "n_neighbors = 43: Accuracy = 0.3054, Training time = 0.02 seconds\n",
            "n_neighbors = 44: Accuracy = 0.3033, Training time = 0.02 seconds\n",
            "n_neighbors = 45: Accuracy = 0.3025, Training time = 0.02 seconds\n",
            "n_neighbors = 46: Accuracy = 0.2979, Training time = 0.02 seconds\n",
            "n_neighbors = 47: Accuracy = 0.2992, Training time = 0.02 seconds\n",
            "n_neighbors = 48: Accuracy = 0.2971, Training time = 0.02 seconds\n",
            "n_neighbors = 49: Accuracy = 0.2950, Training time = 0.02 seconds\n",
            "n_neighbors = 50: Accuracy = 0.2929, Training time = 0.02 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find and print the value of n_neighbors with the highest accuracy\n",
        "best_n = max(results, key=lambda k: results[k]['accuracy'])\n",
        "print(f\"\\nBest n_neighbors: {best_n} with accuracy = {results[best_n]['accuracy']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb9I7UJ4KYUA",
        "outputId": "54e74b29-4727-4c8b-9149-faf7f7b9324b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best n_neighbors: 8 with accuracy = 0.4071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Use PCA + k-NN to reduce the dimension and GridSearchCV to select the optimal number of principal components and k in k-NN.\n",
        "pipe = Pipeline([\n",
        "    ('pca', PCA()),\n",
        "    ('clf', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "parameters = {\n",
        "    'pca__n_components': [2, 4, 6, 8, 10, 15],\n",
        "    'clf__n_neighbors': [5, 8, 10]\n",
        "}\n",
        "\n",
        "# GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(pipe, parameters, cv=5, scoring='accuracy', verbose=1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QF82zxVvOWOR",
        "outputId": "0663edc5-2208-4e1c-ba4d-59a67ca66afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "30 fits failed out of a total of 210.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 353, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\", line 462, in fit_transform\n",
            "    U, S, Vt = self._fit(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\", line 512, in _fit\n",
            "    return self._fit_full(X, n_components)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\", line 526, in _fit_full\n",
            "    raise ValueError(\n",
            "ValueError: n_components=14 must be between 0 and min(n_samples, n_features)=13 with svd_solver='full'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 353, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\", line 462, in fit_transform\n",
            "    U, S, Vt = self._fit(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\", line 512, in _fit\n",
            "    return self._fit_full(X, n_components)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\", line 526, in _fit_full\n",
            "    raise ValueError(\n",
            "ValueError: n_components=15 must be between 0 and min(n_samples, n_features)=13 with svd_solver='full'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.41013889 0.41041667 0.41055556 0.41055556 0.41055556 0.41055556\n",
            " 0.41055556 0.41055556 0.41055556 0.41055556 0.41055556 0.41055556\n",
            "        nan        nan 0.39819444 0.39958333 0.39958333 0.39958333\n",
            " 0.39958333 0.39958333 0.39958333 0.39958333 0.39958333 0.39958333\n",
            " 0.39958333 0.39958333        nan        nan 0.39402778 0.39319444\n",
            " 0.39333333 0.39333333 0.39333333 0.39333333 0.39333333 0.39333333\n",
            " 0.39333333 0.39333333 0.39333333 0.39333333        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('pca', PCA()),\n",
              "                                       ('clf', KNeighborsClassifier())]),\n",
              "             param_grid={'clf__n_neighbors': [5, 8, 10],\n",
              "                         'pca__n_components': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
              "                                               12, 13, 14, 15]},\n",
              "             scoring='accuracy', verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA()),\n",
              "                                       (&#x27;clf&#x27;, KNeighborsClassifier())]),\n",
              "             param_grid={&#x27;clf__n_neighbors&#x27;: [5, 8, 10],\n",
              "                         &#x27;pca__n_components&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
              "                                               12, 13, 14, 15]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA()),\n",
              "                                       (&#x27;clf&#x27;, KNeighborsClassifier())]),\n",
              "             param_grid={&#x27;clf__n_neighbors&#x27;: [5, 8, 10],\n",
              "                         &#x27;pca__n_components&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
              "                                               12, 13, 14, 15]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA()), (&#x27;clf&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Report the best accuracy and parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validated Accuracy:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2GZWFb4OvbI",
        "outputId": "d1610c1c-c888-4169-9914-06718f450d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'clf__n_neighbors': 5, 'pca__n_components': 4}\n",
            "Best Cross-Validated Accuracy: 0.4105555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Using the best estimator with the best parameters, re-evaluate the testing set and measure the time to elapse.\n",
        "best_estimator = grid_search.best_estimator_\n",
        "\n",
        "# Time to evaluate on the testing set\n",
        "start_time = time.time()\n",
        "y_test_pred = best_estimator.predict(X_test)\n",
        "testing_time = time.time() - start_time\n",
        "\n",
        "# Accuracy on the testing set\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Accuracy on the Testing Set:\", accuracy_test)\n",
        "print(\"Testing Time:\", testing_time, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEriDHnUO0Lw",
        "outputId": "e84493d2-1757-4e1a-edf3-8fdd901ffc0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the Testing Set: 0.39458333333333334\n",
            "Testing Time: 0.14912080764770508 seconds\n"
          ]
        }
      ]
    }
  ]
}